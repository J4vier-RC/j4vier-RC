---
title: "Análisis de Regresión Lineal y Pruebas de Hipótesis"
output: html_document
date: "2025-05-13"
---

###                                                                      Javier Ramirez Cervantes

## Utilizando R:
Creamos nuestro DataFrame con los datos requeridos:
```{r}

Ventas_Y = c(200000, 210000, 215000, 220000, 225000, 230000, 235000, 240000, 245000, 250000, 
             255000, 260000, 265000, 270000, 275000, 280000, 285000, 290000, 295000, 300000, 
             305000, 310000, 315000, 320000, 325000, 330000, 335000, 340000, 345000, 350000)

Gasto_Publicidad_X1 = c(20000, 22000, 23000, 25000, 26000, 28000, 29000, 31000, 32000, 33000, 
                        35000, 36000, 37000, 39000, 40000, 42000, 43000, 45000, 46000, 48000, 
                        49000, 51000, 52000, 54000, 55000, 57000, 58000, 60000, 61000, 63000)

Num_Empleados_X2 = c(50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 
                     66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80)

df = data.frame(Ventas_Y, Gasto_Publicidad_X1, Num_Empleados_X2)
df

```
## Paso 1: Análisis Descriptivo de las variables: Analisis descriptivo de las variables proporcionadas
Se realizaran pruebas a cada variable para conocer el comportamiento de estas.

Primero se llaman las librerias necesarias para realizar el analisis
```{r}
library(reticulate)
library(dplyr)
library(gapminder)
```

### Medidas de Tendencia central y dispersión de las variables.

* Variable de Ventas_Y

```{r}
VY <-df %>%
  summarise(Media = mean(Ventas_Y),
            Mediana = median(Ventas_Y), 
            Desviacion = sd(Ventas_Y) )

Rango = range(Ventas_Y) 

VY

Rango

boxplot(Ventas_Y, main="Boxplot de Ventas", col = "red")

```

De acuerdo con los datos anteriores, el valor de la media y la mediana es bastante cercano, lo cual puede indicar un distribucion casi normal de los datos, dato que se contrasta con el grafico de caja el cual parece indicar una distribucion no sesgada. La desviación estandar es normal dado que si se le suma o resta a la mediana, los resultados son similares a los que muestra el boxplot en los limites de la caja. 


* Variable Gasto_en_Publicidad_X1
```{r}
GP <-df %>%
  summarise(Media = mean(Gasto_Publicidad_X1),
            Mediana = median(Gasto_Publicidad_X1), 
            Desviacion = sd(Gasto_Publicidad_X1) )

Rango = range(Gasto_Publicidad_X1) 

GP

Rango

boxplot(Gasto_Publicidad_X1, main="Boxplot de Gasto en Publicidad", col = "blue")


```

De acuerdo con los datos anteriores, el valor de la media y la mediana es bastante cercano,lo cual puede indicar un distribucion casi normal de los datos, dato que se contrasta con el grafico de caja el cual parece indicar una distribucion ligeramente segada hacia la parte superior del grafico de caja, es decir, un sesgo a la derecha. La desviación estandar es un poco alta dado que si se le suma o resta a la mediana, los resultados son cercanos a los que muestra el boxplot en los limites de la caja.


* Variable Numero de Empleados X2
```{r}
NE <-df %>%
  summarise(Media = mean(Num_Empleados_X2),
            Mediana = median(Num_Empleados_X2), 
            Desviacion = sd(Num_Empleados_X2) )

Rango = range(Num_Empleados_X2) 

NE

Rango

boxplot(Num_Empleados_X2, main="Boxplot de Numero de Empleados", col = "green")
```

De acuerdo con los datos anteriores, el valor de la media y la mediana es bastante cercano, lo cual puede indicar un distribucion casi normal de los datos, dato que se contrasta con el grafico de caja el cual parece indicar una distribucion no sesgada. La desviación estandar es normal dado que si se le suma o resta a la mediana, los resultados son similares a los que muestra el boxplot en los limites de la caja. 


## Paso 2: Construcción del Modelo de Regresión Lineal

### Elaboracion del modelo
Se crea un modelo de regresion lineal multiple que explique el comportamiento de la variable Ventas dependiendo de los cambios en las variables de Gasto en Publicidad y Numero de empleados

```{r}
x_train = df[, c("Gasto_Publicidad_X1","Num_Empleados_X2")]
y_train = df['Ventas_Y']
lm <- lm(y_train$Ventas_Y ~ x_train$Gasto_Publicidad_X1 + x_train$Num_Empleados_X2)
print(summary(lm))

```
### Reportando Resultados de los coeficientes
Una vez que se estimo el modelo, los resultados de los coeficientes de determinacion son los siguientes:

R2 = 1 y R2 ajustado = 1

Estos resultados muestran un problema de sobreajuste del modelo.

## Paso 3: Pruebas de Hipótesis sobre los Coeficientes
En esta parte del modelo se verifica la significancia de las variables para la estimacion del modelo.

Resultados del modelo:
```{r}
print(summary(lm))
```

Hipotesis nula: H0 -> El coeficiente no es significativo  
Hipotesis alternativa: Ha -> El coeficiente es significativo

Reglas de decision: p-value > 0.05 No se rechaza H0 // p-value < 0.05 Se rechaza H0

Segun los resultados de los p-values de cada uno de los coeficientes, los resultados
son los siguientes:

* Coeficiente del intercepto = 2e-16 < 0.05 , por lo cual se rechaza la H0 y el coeficiente
es significativo

* Coeficiente del Gasto en Publicidad = 0.00236 < 0.05 , por lo cual se rechaza la H0 y el coeficiente es significativo

* Coeficiente del Numero de Empleados = 2e-16 < 0.05 , por lo cual se rechaza la H0 y el coeficiente es significativo


## Paso 4: Análisis de los Residuos
En esta parte del analisis se realizan las pruebas sobre los residuos del modelo estimado

### Prueba de normalidad, Jarque-Bera
```{r}
library(tseries)
jarque.bera.test(lm$residuals)
```
Hipotesis nula: H0 -> Sesgo = 0 y Kurtosis = 3 -> Los residuos se distribuyen como una normal

Hipotesis alternativa: Ha -> Sesgo =/ 0 y/o Kurtosis =/ 3 -> Los residuos no se distribuyen como una normal

Reglas de decision: p-value > 0.05 No se rechaza H0 
                    p-value < 0.05 Se rechaza H0

* Jarque-Bera p-value = 2.2e-16 < 0.05 , por lo cual se rechaza la H0 y el los residuos no se
distribuyen como una normal


### Prueba de Homocedasticidad, Breusch-Pagan
```{r}
library(lmtest)
bptest(lm)

```
Hipotesis nula: H0 -> Homocedasticidad - La varianza de los residuos es constante  
Hipotesis alternativa: Ha -> Heterocedasticidad -  La varianza de los residuos no es constante

Reglas de decision: p-value > 0.05 No se rechaza H0 
                    p-value < 0.05 Se rechaza H0

* Breusch-Pagan p-value = 0.001657 < 0.05 , por lo cual se rechaza la H0 y la varianza de los residuos no es constante.


### Prueba de autocorrelacion, Durbin-Warson:
```{r}
library(car)

durbinWatsonTest(lm)

## Correlogramas
library(lmtest)
acf(lm$residuals)

```

Hipotesis nula: H0 -> No autocorrelacion - los residuos no estan autocorrelacionados   
Hipotesis alternativa: Ha -> Autocorrelacion - los residuos estan autocorrelacionados

Reglas de decision: p-value > 0.05 No se rechaza H0 
                    p-value < 0.05 Se rechaza H0

* Breusch-Pagan p-value = 0.23 > 0.05 , por lo cual no se rechaza la H0 y los residuos no
estan autocorrelacionados

Asimismo el correlograma muestra que no hay problemas de autocorrelacion.

## Paso 5: Conclusiones

Resumiendo los resultados de la pruebas del modelo, en la primera parte de la descripcion de las variables, la mayoria de ellas muestran una distribucion casi normal, salvo la variable de Gasto en Publicidad que si muestra cierto sesgo a la derecha. En la elaboración del modelo de regresion lineal multiple, los resultados de los coeficientes de determinacion de R2 y R2 ajustado tienen un valor de 1 en ambos casos, lo cual muestra un problema de sobreajuste del modelo. En la siguiente prueba de significancia de los coeficientes, de acuerdo con los resultados, el intercepto, y la variables de Gasto en Publicidad y Numero de Empleados son significativos para la estimacion del modelo. 
En las siguientes pruebas sobre el analisis de los residuos del modelo, los resultados arrojaron mas irregularidades. El modelo no tiene una distribucion normal de sus residuos, y la varianza de estos no es constante. A pesar de los resultados, los residuos no muestran problemas de autocorrelacion

Para buscar una razon a los problemas del modelo, se realiza la prueba de multicolinealidad:

### Prueba del VIF (Factor de inflacion de la varianza)
```{r}
library(car)
vif(lm)
```
Criterio de decision:

VIF < 5 -> Baja Multicolinealidad  
VIF > 5 -> Alta Multicolinealidad

De acuerdo con los resultados, ambas variables explicativas presentan altos problemas de multicolinealidad, lo cual podria ser la causada de que los residuos no tengan una distribucion normal, el problema de la heterocedasticidad y sobreajuste del modelo. Para verificar que esta sea la causa de dichos problemas, se tendria que hacer un nuevo modelo eliminando algunas de las variables debido a que existe multicolinealidad en ambos casos.
